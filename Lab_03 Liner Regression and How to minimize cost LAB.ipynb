{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdAPWcMJQ4+8XacvA9IUZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeDongGeon1996/TensorFlow/blob/master/study-note/Lab_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL-5Q2YD1ENj",
        "colab_type": "text"
      },
      "source": [
        "# Lab-03 Liner Regression and How to minimize cost LAB\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq6G90Cu1BTH",
        "colab_type": "code",
        "outputId": "5b872172-5622-4e30-e0f3-8364611f9a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KClAeqXM1gsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "ee0be92f-8999-40c6-ad9d-2a0a6133ee3c"
      },
      "source": [
        "def cost_func_ex(w,b,x,y):\n",
        "  sum = 0\n",
        "  for i in range(len(x)):\n",
        "    x += (w*x[i] + b - y[i]) ** 2\n",
        "\n",
        "  return sum / (2*len(x))\n",
        "\n",
        "# random값을 생성.\n",
        "# 정규분포의 중간값과 표준편차를 지정할 수있음.\n",
        "for i in range(10):\n",
        "  print(tf.random.normal([1], 5, 2))\n",
        "\n",
        "\n",
        "# random값을 생성.\n",
        "# 정규분표를 따라 생성하나 min max를 지정하여 생성가능.\n",
        "print(\"**************************\")\n",
        "\n",
        "for i in range(10):\n",
        "  print(tf.random.uniform([1], 3, 7))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([7.1337605], shape=(1,), dtype=float32)\n",
            "tf.Tensor([1.3917427], shape=(1,), dtype=float32)\n",
            "tf.Tensor([8.397954], shape=(1,), dtype=float32)\n",
            "tf.Tensor([8.22798], shape=(1,), dtype=float32)\n",
            "tf.Tensor([2.6509006], shape=(1,), dtype=float32)\n",
            "tf.Tensor([9.4969845], shape=(1,), dtype=float32)\n",
            "tf.Tensor([3.8594117], shape=(1,), dtype=float32)\n",
            "tf.Tensor([6.665659], shape=(1,), dtype=float32)\n",
            "tf.Tensor([7.698511], shape=(1,), dtype=float32)\n",
            "tf.Tensor([0.74439764], shape=(1,), dtype=float32)\n",
            "**************************\n",
            "tf.Tensor([4.2065926], shape=(1,), dtype=float32)\n",
            "tf.Tensor([3.0459785], shape=(1,), dtype=float32)\n",
            "tf.Tensor([6.183558], shape=(1,), dtype=float32)\n",
            "tf.Tensor([5.6173], shape=(1,), dtype=float32)\n",
            "tf.Tensor([4.893801], shape=(1,), dtype=float32)\n",
            "tf.Tensor([4.676357], shape=(1,), dtype=float32)\n",
            "tf.Tensor([4.0187635], shape=(1,), dtype=float32)\n",
            "tf.Tensor([5.341142], shape=(1,), dtype=float32)\n",
            "tf.Tensor([5.215643], shape=(1,), dtype=float32)\n",
            "tf.Tensor([5.8761106], shape=(1,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3R0QYHD6ScZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "a37db957-999c-4a8f-f26d-6eb96fe25f5b"
      },
      "source": [
        "tf.random.set_seed(0)\n",
        "\n",
        "epoch = 500\n",
        "learning_rate = 0.01\n",
        "W = tf.Variable(tf.random.uniform([1], -100, 100))\n",
        "\n",
        "\n",
        "x = np.array([6,7,8])\n",
        "y = np.array([6,7,8])\n",
        "\n",
        "for step in range(epoch):\n",
        "  hx = W*x\n",
        "  cost = tf.reduce_mean(tf.square(hx - y))\n",
        "  gradient = tf.reduce_mean(tf.multiply((hx - y), x))\n",
        "  W.assign(W - learning_rate * gradient)\n",
        "\n",
        "\n",
        "  \n",
        "  # 이 코드도 돼야하는거 아닌가...\n",
        "  # W.assign_sub(learning_rate * gradient)\n",
        "  \n",
        "  if step % 50 == 0:\n",
        "    print(\"{:5} | {:10.4f} | {:10.4f}\".format(step, cost, W.numpy()[0]))\n",
        "\n",
        "# Predict\n",
        "print(W * [7,8,9])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 | 90154.1250 |   -20.4445\n",
            "   50 |     0.0000 |     1.0000\n",
            "  100 |     0.0000 |     1.0000\n",
            "  150 |     0.0000 |     1.0000\n",
            "  200 |     0.0000 |     1.0000\n",
            "  250 |     0.0000 |     1.0000\n",
            "  300 |     0.0000 |     1.0000\n",
            "  350 |     0.0000 |     1.0000\n",
            "  400 |     0.0000 |     1.0000\n",
            "  450 |     0.0000 |     1.0000\n",
            "tf.Tensor([7. 8. 9.], shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbhBwVHLQscf",
        "colab_type": "text"
      },
      "source": [
        "### 강의에서는 H(x) = Wx로 두고 했지만,\n",
        "### H(x) = Wx + b로 두고 해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7iG4j4SPd6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.03\n",
        "epoch = 30000\n",
        "W = tf.Variable(tf.random.uniform([1], -5, 10))\n",
        "b = tf.Variable(tf.random.uniform([1], 2, 6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zliVvD6-OOCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c1ad720-eca3-4f99-9680-47f602d40fc9"
      },
      "source": [
        "\n",
        "x = np.array([6,7,8])\n",
        "y = np.array([10,11,12])\n",
        "\n",
        "for step in range(epoch):\n",
        "  hx = W*x + b\n",
        "  cost = tf.reduce_mean(tf.square(hx - y))\n",
        "  # x에대한 편미분\n",
        "  gradient = tf.reduce_mean(tf.multiply((hx - y), x))\n",
        "  # b에대한 편미분\n",
        "  gradient_b = tf.reduce_mean(tf.multiply((hx - y), 1))\n",
        "\n",
        "  W.assign(W - learning_rate * gradient)  \n",
        "  b.assign(b - learning_rate * gradient_b)\n",
        "  \n",
        "  if step % 500 == 0:\n",
        "    print(\"{:5} | {:10.4f} | {:10.4f} | {:10.4f}\".format(step, cost, W.numpy()[0], b.numpy()[0]))\n",
        "\n",
        "# Predict\n",
        "print(W * [7,8,9] + b)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |   780.0557 |    -0.6740 |     1.2678\n",
            "  500 |     0.0542 |     1.2832 |     1.9910\n",
            " 1000 |     0.0365 |     1.2325 |     2.3510\n",
            " 1500 |     0.0246 |     1.1908 |     2.6465\n",
            " 2000 |     0.0166 |     1.1566 |     2.8890\n",
            " 2500 |     0.0112 |     1.1286 |     3.0881\n",
            " 3000 |     0.0075 |     1.1055 |     3.2515\n",
            " 3500 |     0.0051 |     1.0866 |     3.3856\n",
            " 4000 |     0.0034 |     1.0711 |     3.4957\n",
            " 4500 |     0.0023 |     1.0584 |     3.5861\n",
            " 5000 |     0.0016 |     1.0479 |     3.6602\n",
            " 5500 |     0.0010 |     1.0393 |     3.7211\n",
            " 6000 |     0.0007 |     1.0323 |     3.7711\n",
            " 6500 |     0.0005 |     1.0265 |     3.8121\n",
            " 7000 |     0.0003 |     1.0217 |     3.8458\n",
            " 7500 |     0.0002 |     1.0178 |     3.8734\n",
            " 8000 |     0.0001 |     1.0146 |     3.8961\n",
            " 8500 |     0.0001 |     1.0120 |     3.9147\n",
            " 9000 |     0.0001 |     1.0099 |     3.9300\n",
            " 9500 |     0.0000 |     1.0081 |     3.9425\n",
            "10000 |     0.0000 |     1.0066 |     3.9528\n",
            "10500 |     0.0000 |     1.0055 |     3.9613\n",
            "11000 |     0.0000 |     1.0045 |     3.9682\n",
            "11500 |     0.0000 |     1.0037 |     3.9739\n",
            "12000 |     0.0000 |     1.0030 |     3.9786\n",
            "12500 |     0.0000 |     1.0025 |     3.9824\n",
            "13000 |     0.0000 |     1.0020 |     3.9856\n",
            "13500 |     0.0000 |     1.0017 |     3.9882\n",
            "14000 |     0.0000 |     1.0014 |     3.9903\n",
            "14500 |     0.0000 |     1.0011 |     3.9920\n",
            "15000 |     0.0000 |     1.0009 |     3.9934\n",
            "15500 |     0.0000 |     1.0008 |     3.9946\n",
            "16000 |     0.0000 |     1.0006 |     3.9956\n",
            "16500 |     0.0000 |     1.0005 |     3.9964\n",
            "17000 |     0.0000 |     1.0004 |     3.9970\n",
            "17500 |     0.0000 |     1.0003 |     3.9976\n",
            "18000 |     0.0000 |     1.0003 |     3.9980\n",
            "18500 |     0.0000 |     1.0002 |     3.9984\n",
            "19000 |     0.0000 |     1.0002 |     3.9986\n",
            "19500 |     0.0000 |     1.0002 |     3.9989\n",
            "20000 |     0.0000 |     1.0001 |     3.9991\n",
            "20500 |     0.0000 |     1.0001 |     3.9992\n",
            "21000 |     0.0000 |     1.0001 |     3.9994\n",
            "21500 |     0.0000 |     1.0001 |     3.9995\n",
            "22000 |     0.0000 |     1.0001 |     3.9996\n",
            "22500 |     0.0000 |     1.0000 |     3.9997\n",
            "23000 |     0.0000 |     1.0000 |     3.9997\n",
            "23500 |     0.0000 |     1.0000 |     3.9997\n",
            "24000 |     0.0000 |     1.0000 |     3.9997\n",
            "24500 |     0.0000 |     1.0000 |     3.9997\n",
            "25000 |     0.0000 |     1.0000 |     3.9997\n",
            "25500 |     0.0000 |     1.0000 |     3.9997\n",
            "26000 |     0.0000 |     1.0000 |     3.9997\n",
            "26500 |     0.0000 |     1.0000 |     3.9997\n",
            "27000 |     0.0000 |     1.0000 |     3.9997\n",
            "27500 |     0.0000 |     1.0000 |     3.9997\n",
            "28000 |     0.0000 |     1.0000 |     3.9997\n",
            "28500 |     0.0000 |     1.0000 |     3.9997\n",
            "29000 |     0.0000 |     1.0000 |     3.9997\n",
            "29500 |     0.0000 |     1.0000 |     3.9997\n",
            "tf.Tensor([10.999996 12.000039 13.000082], shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRD-xOa5Olr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}