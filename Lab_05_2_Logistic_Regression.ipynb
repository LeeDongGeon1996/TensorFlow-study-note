{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-05-2 Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPG+n8Hc6y7DQCqqgdIMZIh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeDongGeon1996/TensorFlow/blob/master/study-note/Lab_05_2_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPdB7Uc-hyUr",
        "colab_type": "text"
      },
      "source": [
        "# Lab-05-2 Logistic Regression\n",
        "\n",
        "## Cost Function\n",
        "* Weight값은 초기에 랜덤한 값으로 시작한다.<br />\n",
        "* 이러한 Weight를 최적값을 같도록 하는 함수...<br />\n",
        "그냥 cost(error)를 계산하는 함수이나 이 함수를 토대로 <br />\n",
        "최적의 `parameter` (= weight?)를 계산하기 때문에 이렇게 설명된 것 같다.  <br />\n",
        "\n",
        "> 우리는 data set을 이용하여 최적의 parameter를 가진 Hypothesis를 구할 수 있다. -> `Linear function`<br />\n",
        " `Linear function에서 나온 값`을 input으로 `Logistic Function`에 넣으면 logistic regression의 cost값을 구할 수 있다. \n",
        ">> 즉, 더 쉽게 내가 이해한대로 풀어쓰자면,<br />\n",
        " `Linear function` 인 $h(x)$를  `Logistic Function`에 input으로 넣는다면 <br />\n",
        " 이것의 `label(정답)`이 1일때 1에서 얼마나 먼 지(오차가 얼마인지),<br />\n",
        "  `label`이 0이라면 0에서 얼마나 먼 지, 를 구할수 있다.<br />\n",
        "  **즉, Logistic regression의 cost를 구할 수 있는 것이다.**<br />\n",
        ">>> 그러한 `Logistic regression cost function`는<br />\n",
        "`label`이 0일때는 1에서 무한으로 수렴하고,<br />\n",
        "`label`이 1일때는 0에서 무한으로 수렴하는 로그함수를 사용한다.<br />\n",
        "이렇게 되면 convex한 함수가 된다.<br />\n",
        "\n",
        "\n",
        "\n",
        "## Optimization\n",
        " = how to minimize the cost function<br />\n",
        " `cost function`을 최솟값을 갖게하는 작업을  `Optimization`이라고 한다.<br />\n",
        " 즉, 우리가 이전에 사용하였던 `Gradient Descent`가 그 예 중에 하나일뿐이었던 것이다.<br />\n",
        "\n",
        "##Eager Execution\n",
        "* Gragient Tape\n",
        "* Gragient Descent Optimizer\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMy6bDxphv9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}