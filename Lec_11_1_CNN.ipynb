{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec_11_1: CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDNzmzRrL9jEMUSnt3Vq9s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeDongGeon1996/TensorFlow-study-note/blob/master/Lec_11_1_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_td3sdraMmq",
        "colab_type": "text"
      },
      "source": [
        "# Lec_11_1: ConvNet의 Conv 레이어 만들기\n",
        "\n",
        "* network에는 여러종류가 있었다.\n",
        " * Forward network : 일자로 쭉 다음layer로 넘어가는 network\n",
        " * 등등..\n",
        "\n",
        " # Convolutional Network\n",
        "  * 입력 이미지가 있을 때, \n",
        "  * `Convolution layer` : 이미지를 일정 크기로 잘라서 각가의 입력으로 network에 넣는다.\n",
        "   > * 요기서 일정크기라함은 `filter` size이다. = `window size` \n",
        "   > * 하나의 필터는 Conv layer를 지나면 하나의 값이 된다.\n",
        "   > * 필터를 통해 이미지를 순환하면서 network의 입력값으로 넣는다. (stride값만큼.)\n",
        "   > * `stride` : filter를 한번 이동하는 거리.\n",
        "    * `pooling layer` : ?\n",
        "  \n",
        " ## 그렇다면 Convolution layer를 통과하면 몇개의 input값이 들어가게 될까?\n",
        "  * 사실 그냥 계산 하면된다.\n",
        "   > * N : Image size\n",
        "    * F: Filter size\n",
        "    * output size = $\\frac{N-F}{stride} + 1$\n",
        "\n",
        "  #### Conv layer를 통과하면 이미지의 크기가 급격히 줄어들어 정보가 손실되는 경우가 발생할 수 있다.\n",
        "  > 입력이미지의 테두리에 `padding`을 추가한다.\n",
        "\n",
        "\n",
        " * 실제 Convolution Layer를 통과할때는 여러개의 필터를 사용한다.\n",
        "\n",
        " #### 그렇다면 \n",
        "  그 때의 weight값의 갯수는 filter갯수를 곱한것만큰 늘어난다.\n",
        "\n",
        "\n",
        "  # Max pooling\n",
        "   * pooling layer는 sampling하는 것이라고 할 수 있다.\n",
        "   * convolution layer에서 나온  output을 샘플링하여 <br />\n",
        "  resize하는 작업이다.\n",
        "\n",
        "\n",
        " # Network 구성.\n",
        "  * Conv - ReLU - Conv - ReLu - POOL 이런 순으로 구성되는 듯하다. 일반적으로\n",
        "  * 이미지를 분류하는 model을 만드는 과정이라면 마지막 output layer에서 <br />\n",
        "  FC layer(with acti = softmax)를 사용할듯하다.\n",
        "  \n",
        "  > * `feature extraction` : `conv`, `pooling(subsampling)`과 같은 연산이 이루어지는 layer들 \n",
        "  * `classification` : `feature extraction`이후 실제 분류작업을하는 layer들.  \n",
        "\n",
        "# Example\n",
        " * Yann LeCun이 처음 Convolution을 사용하였다.(LeNet-5 in 1998)\n",
        " * AlexNet in 2012 \n",
        " > * [conv] - [Max-pool] - [norm] - [FC] 순으로 구성.\n",
        "  * 최근에는 norm layer는 잘 사용되지 않는다.\n",
        "  * ReLU를 처음 사용함.\n",
        "  * 7개의 이와같은 model을 만들어 Ensemble함.\n",
        "\n",
        " * GoogLeNet in 2014\n",
        " * ResNet in 2015\n",
        "  > * Fast forward 기법을 사용하여 무려 152layer를 학습시킬 수 있었다.\n",
        "  * 그래도 GPU 8개로 2~3주 걸림.\n",
        "\n",
        " * Convolution network로 이미지만 처리할 수 있는 것이 아니다.\n",
        "  > text처리도 가능.\n",
        "\n",
        " * AlphaGo도 Conv사용\n",
        " \n"
      ]
    }
  ]
}