{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment_04_ReLU with zero weight.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPobdZNl+ye+awnzTAdBQCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeDongGeon1996/TensorFlow-study-note/blob/master/my-practice/Experiment_04_ReLU_with_zero_weight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuSK9fwFf3Em",
        "colab_type": "text"
      },
      "source": [
        "# Experiment_04_ReLU with zero weight\n",
        "\n",
        " * Conclusion\n",
        " > cannot process learning with zero-weght.\n",
        "\n",
        " ```\n",
        "Epoch : 0, Loss : 1.022075\n",
        "Epoch : 1000, Loss : 0.693167\n",
        "Epoch : 2000, Loss : 0.693147\n",
        "Epoch : 3000, Loss : 0.693147\n",
        "Epoch : 4000, Loss : 0.693147\n",
        "Epoch : 5000, Loss : 0.693147\n",
        "Epoch : 6000, Loss : 0.693147\n",
        "Epoch : 7000, Loss : 0.693147\n",
        "Epoch : 8000, Loss : 0.693147\n",
        " ``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm0XL5IVRV39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d3f8432a-5daa-4940-c2c8-3b9f84343f17"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "print(tf.__version__)\n",
        "x_data = [[0, 0],\n",
        "          [0, 1],\n",
        "          [1, 0],\n",
        "          [1, 1]]\n",
        "y_data = [[0],\n",
        "          [1],\n",
        "          [1],\n",
        "          [0]]\n",
        "\n",
        "plt.scatter(x_data[0][0],x_data[0][1], c='red' , marker='^')\n",
        "plt.scatter(x_data[3][0],x_data[3][1], c='red' , marker='^')\n",
        "plt.scatter(x_data[1][0],x_data[1][1], c='blue' , marker='^')\n",
        "plt.scatter(x_data[2][0],x_data[2][1], c='blue' , marker='^')\n",
        "\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()\n",
        "\n",
        "def preprocess_data(features, labels):\n",
        "    features = tf.cast(features, tf.float32)\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    return features, labels"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnEEgSY0zCCSpcQaBJDXOIJCkxv0/Uy24uOwjAdMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRQ1fsOzRZwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(777)  # for reproducibility\n",
        "\n",
        "#w_layer1 = tf.Variable(tf.zeros([2,2], dtype=tf.float32))\n",
        "#b_layer1 = tf.Variable(tf.zeros([1,2], dtype=tf.float32))\n",
        "\n",
        "\n",
        "w_layer1 = tf.Variable(tf.random.normal([2,2], dtype=tf.float32))\n",
        "b_layer1 = tf.Variable(tf.random.normal([1,2], dtype=tf.float32))\n",
        "w_layer2 = tf.Variable(tf.random.normal([2,2], dtype=tf.float32))\n",
        "b_layer2 = tf.Variable(tf.random.normal([1,2], dtype=tf.float32))\n",
        "\n",
        "w_output = tf.Variable(tf.random.normal([2,1], dtype=tf.float32))\n",
        "b_output = tf.Variable(tf.random.normal([1,], dtype=tf.float32))\n",
        "\n",
        "\n",
        "\n",
        "def hypothesis(features):\n",
        "  layer1 = tf.nn.sigmoid(tf.matmul(features, w_layer1) + b_layer1)\n",
        "  layer2 = tf.nn.relu(tf.matmul(layer1, w_layer2) + b_layer2)\n",
        "  output_layer = tf.nn.sigmoid(tf.matmul(layer2, w_output) + b_output)\n",
        "\n",
        "  return output_layer\n",
        "\n",
        "def get_cost(features, labels):\n",
        "  output = hypothesis(features)\n",
        "  cost = labels * tf.math.log(output) + (1-labels) * tf.math.log(1-output)\n",
        "  mean_cost = -tf.reduce_mean(cost)\n",
        "\n",
        "  return mean_cost\n",
        "\n",
        "def get_accuracy(features, labels):\n",
        "  output = hypothesis(features)\n",
        "  output = tf.cast(output > 0.5, dtype=tf.float32)\n",
        "  accuracy = tf.reduce_mean(tf.cast(tf.equal(output,labels), dtype=tf.float32))\n",
        "  \n",
        "  return accuracy\n",
        "\n",
        "def fit(dataset, epoch=50000, verbose=1000):\n",
        "  for i in range(epoch):\n",
        "    for features, labels in dataset:    \n",
        "      with tf.GradientTape() as g:\n",
        "        cost = get_cost(features, labels)\n",
        "        grads = g.gradient(cost, [w_layer1, w_output, b_layer1, b_output])\n",
        "        optimizer.apply_gradients(grads_and_vars = zip(grads, [w_layer1, w_output, b_layer1, b_output]))\n",
        "\n",
        "      if((i % verbose) == 0):\n",
        "        print(\"Epoch : {}, Loss : {:.6f}\".format(i, cost))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhaFHFe8SEcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "outputId": "db8c1d6f-af8c-4c1e-fd6a-a99738d9842c"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
        "x, y = preprocess_data(x_data, y_data)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(len(x_data))\n",
        "fit(dataset)\n",
        "\n",
        "test_acc = get_accuracy(x, y)\n",
        "print('test accr : {}'.format(test_acc))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0, Loss : 0.950134\n",
            "Epoch : 1000, Loss : 0.519776\n",
            "Epoch : 2000, Loss : 0.506147\n",
            "Epoch : 3000, Loss : 0.498170\n",
            "Epoch : 4000, Loss : 0.492926\n",
            "Epoch : 5000, Loss : 0.489825\n",
            "Epoch : 6000, Loss : 0.487855\n",
            "Epoch : 7000, Loss : 0.486414\n",
            "Epoch : 8000, Loss : 0.485317\n",
            "Epoch : 9000, Loss : 0.484455\n",
            "Epoch : 10000, Loss : 0.483760\n",
            "Epoch : 11000, Loss : 0.483188\n",
            "Epoch : 12000, Loss : 0.482709\n",
            "Epoch : 13000, Loss : 0.482302\n",
            "Epoch : 14000, Loss : 0.481953\n",
            "Epoch : 15000, Loss : 0.481649\n",
            "Epoch : 16000, Loss : 0.481384\n",
            "Epoch : 17000, Loss : 0.481149\n",
            "Epoch : 18000, Loss : 0.480940\n",
            "Epoch : 19000, Loss : 0.480753\n",
            "Epoch : 20000, Loss : 0.480584\n",
            "Epoch : 21000, Loss : 0.480432\n",
            "Epoch : 22000, Loss : 0.480293\n",
            "Epoch : 23000, Loss : 0.480166\n",
            "Epoch : 24000, Loss : 0.480050\n",
            "Epoch : 25000, Loss : 0.479943\n",
            "Epoch : 26000, Loss : 0.479844\n",
            "Epoch : 27000, Loss : 0.479753\n",
            "Epoch : 28000, Loss : 0.479668\n",
            "Epoch : 29000, Loss : 0.479589\n",
            "Epoch : 30000, Loss : 0.479515\n",
            "Epoch : 31000, Loss : 0.479446\n",
            "Epoch : 32000, Loss : 0.479382\n",
            "Epoch : 33000, Loss : 0.479321\n",
            "Epoch : 34000, Loss : 0.479264\n",
            "Epoch : 35000, Loss : 0.479210\n",
            "Epoch : 36000, Loss : 0.479159\n",
            "Epoch : 37000, Loss : 0.479111\n",
            "Epoch : 38000, Loss : 0.479065\n",
            "Epoch : 39000, Loss : 0.479022\n",
            "Epoch : 40000, Loss : 0.478981\n",
            "Epoch : 41000, Loss : 0.478942\n",
            "Epoch : 42000, Loss : 0.478905\n",
            "Epoch : 43000, Loss : 0.478869\n",
            "Epoch : 44000, Loss : 0.478835\n",
            "Epoch : 45000, Loss : 0.478803\n",
            "Epoch : 46000, Loss : 0.478772\n",
            "Epoch : 47000, Loss : 0.478742\n",
            "Epoch : 48000, Loss : 0.478714\n",
            "Epoch : 49000, Loss : 0.478687\n",
            "test accr : 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUGkKmSQV77q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}