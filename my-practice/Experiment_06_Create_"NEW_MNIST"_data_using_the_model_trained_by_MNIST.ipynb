{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Experiment_06_Create \"NEW MNIST\" data using the model trained by MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeDongGeon1996/TensorFlow-study-note/blob/master/my-practice/Experiment_06_Create_%22NEW_MNIST%22_data_using_the_model_trained_by_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDjkHxUg7sJQ",
        "colab_type": "text"
      },
      "source": [
        "# Experiment_06_Create \"NEW MNIST\" data using the model trained by MNIST\n",
        "\n",
        "> ## conclustion\n",
        " * It doesn't work.... :(\n",
        " * [input] - [new model] ---[fetch created image]--- [trained model] - [output]\n",
        " * My goal was the new model makes new MNIST data image.\n",
        " * but created images didn't look like MNIST image..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDvyNtgQbX9O",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0tHjWnybX9R",
        "colab_type": "code",
        "outputId": "152da350-d13f-42f0-f797-653c323cdda4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kvw3xLTbX9Y",
        "colab_type": "text"
      },
      "source": [
        "## Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ5QmA9GbX9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 1\n",
        "batch_size = 100\n",
        "\n",
        "tf.random.set_seed(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jisQ_Q8bX9f",
        "colab_type": "text"
      },
      "source": [
        "## Creating a Checkpoint Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVK4MBJMbX9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'minst_cnn_func'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6zs4GX6bX9l",
        "colab_type": "text"
      },
      "source": [
        "## MNIST/Fashion MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlATZgZWbX9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## MNIST Dataset #########################################################\n",
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "##########################################################################\n",
        "\n",
        "## Fashion MNIST Dataset #################################################\n",
        "#mnist = keras.datasets.fashion_mnist\n",
        "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "##########################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBkkbrrZbX9r",
        "colab_type": "text"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9ETl5FJbX9t",
        "colab_type": "code",
        "outputId": "ef552afb-09f3-4f1c-9ba3-d64670dae83c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    \n",
        "    \n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "    \n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)    \n",
        "    \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
        "                buffer_size=100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9caP6XQGbX9v",
        "colab_type": "text"
      },
      "source": [
        "## Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_FDOv8ZbX9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    inputs = keras.Input(shape=(28, 28, 1))\n",
        "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(inputs)\n",
        "    pool1 = keras.layers.MaxPool2D(padding='SAME')(conv1)\n",
        "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(pool1)\n",
        "    pool2 = keras.layers.MaxPool2D(padding='SAME')(conv2)\n",
        "    conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)(pool2)\n",
        "    pool3 = keras.layers.MaxPool2D(padding='SAME')(conv3)\n",
        "    pool3_flat = keras.layers.Flatten()(pool3)\n",
        "    dense4 = keras.layers.Dense(units=256, activation=tf.nn.relu)(pool3_flat)\n",
        "    drop4 = keras.layers.Dropout(rate=0.4)(dense4)\n",
        "    logits = keras.layers.Dense(units=10)(drop4)\n",
        "    return keras.Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JWpw6SQbX9z",
        "colab_type": "code",
        "outputId": "1d0e6202-1672-46dd-a360-a46cd8ecb39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 619,786\n",
            "Trainable params: 619,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GBpVtuubX94",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eTu90xxbX95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def loss_fn(model, images, labels):\n",
        "    logits = model(images, training=True)\n",
        "    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n",
        "        y_pred=logits, y_true=labels, from_logits=True))    \n",
        "    return loss   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEfgSAwXbX99",
        "colab_type": "text"
      },
      "source": [
        "## Calculate Gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I1rV_iqbX9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "    return tape.gradient(loss, model.variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1SVUQQ2bX-C",
        "colab_type": "text"
      },
      "source": [
        "## Caculating Model's Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmTKoq30bX-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMMKtIv3bX-H",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIYI61cjbX-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL_r0PRvbX-M",
        "colab_type": "text"
      },
      "source": [
        "## Creating a Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2yBgpT4bX-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = tf.train.Checkpoint(cnn=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKgHKwGobX-R",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VhtjKlPbX-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train(model, images, labels):\n",
        "    grads = grad(model, images, labels)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwDoRAAjm2W5",
        "colab_type": "code",
        "outputId": "1925ed2e-e939-4757-eecd-aae6763efdc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model.fit(x=train_dataset, epochs=3, validation_data=test_dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 600 steps, validate for 100 steps\n",
            "Epoch 1/3\n",
            "600/600 [==============================] - 98s 164ms/step - loss: 0.1410 - accuracy: 0.9562 - val_loss: 0.0404 - val_accuracy: 0.9861\n",
            "Epoch 2/3\n",
            "600/600 [==============================] - 98s 163ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.0242 - val_accuracy: 0.9920\n",
            "Epoch 3/3\n",
            "600/600 [==============================] - 98s 164ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 0.0335 - val_accuracy: 0.9891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e8388ee10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juORMInJ5QOn",
        "colab_type": "text"
      },
      "source": [
        "## Save trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoA3vUd5hk3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e37de984-3540-45b3-baff-acc18a198ebe"
      },
      "source": [
        "model_path = 'my-save/saved.h5'\n",
        "!rm -r my-save\n",
        "!mkdir my-save\n",
        "model.save('my-save/saved.h5')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'my-save': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjnD7QeeiLOo",
        "colab_type": "code",
        "outputId": "d71cb937-ab40-4689-c94d-982212ac2ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints  my-save  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJP8iSXL5Ueu",
        "colab_type": "text"
      },
      "source": [
        "## Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFBNGT-HiXz4",
        "colab_type": "code",
        "outputId": "65907ef9-6aa0-40f1-acf8-df9cb54452d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "new1_model = tf.keras.models.load_model(model_path)\n",
        "new1_model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 619,786\n",
            "Trainable params: 619,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqXWnMAWivLA",
        "colab_type": "code",
        "outputId": "f2dfa02f-651b-4885-a9d4-c2cf7516ac62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "evaluate(new1_model,test_images, test_labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9891>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld7bnbLr6ENe",
        "colab_type": "text"
      },
      "source": [
        "## Create new model to make MNIST image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YZCjdvZpq9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm_as_activation(x):\n",
        "  #이미지 인풋인 상황과 동일하게 만들어줘야함.\n",
        "  norm = (x-tf.math.reduce_min(x))/(tf.math.reduce_max(x) - tf.math.reduce_min(x))\n",
        "  #100은 batch size를 의미\n",
        "  return tf.reshape(norm, (100,28,28,1))\n",
        "\n",
        "def create_image_model(trained_model):\n",
        "  inputs = keras.Input(shape=(10,))\n",
        "  dense1 = keras.layers.Dense(units=256, activation=tf.nn.relu)(inputs)\n",
        "  dense2 = keras.layers.Dense(units=512, activation=tf.nn.relu)(dense1)\n",
        "  dense3 = keras.layers.Dense(units=1024, activation=tf.nn.relu)(dense2)\n",
        "  drop1 = keras.layers.Dropout(rate=0.4)(dense3)\n",
        "  logits = keras.layers.Dense(units=784)(drop1)\n",
        "\n",
        "  activation = keras.layers.Activation(norm_as_activation)(logits)\n",
        "  trained_output = trained_model(activation, training=False)\n",
        "  return keras.Model(inputs=inputs, outputs=logits), keras.Model(inputs=inputs, outputs=trained_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fLkRFa76KX0",
        "colab_type": "text"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSEZMWxpyZuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trained_model = tf.keras.models.load_model(model_path)\n",
        "new_model, ensemble_model = create_image_model(trained_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVXKz-Xn6Oa8",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuzuhSMW4V9l",
        "colab_type": "code",
        "outputId": "1a4db3d5-290a-4053-8f62-5b3e4fc74248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "new_optimizer = keras.optimizers.Adam()\n",
        "new_train_labels = train_labels.copy()\n",
        "print(new_train_labels)\n",
        "\n",
        "ensemble_model.compile(optimizer=new_optimizer, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "ensemble_model.fit(new_train_labels, train_labels, batch_size=100)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n",
            "Train on 60000 samples\n",
            "60000/60000 [==============================] - 131s 2ms/sample - loss: 0.0154 - accuracy: 0.9957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e80ff6898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkkNVeZZ7cui",
        "colab_type": "text"
      },
      "source": [
        "## Show images created by the new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syJGlj-Dzwvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0721f32a-0e9d-48f7-d4a8-a2a9d5e8bc52"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def norm_as_image(x):\n",
        "  #이미지 인풋인 상황과 동일하게 만들어줘야함.\n",
        "  norm = ((x-tf.math.reduce_min(x))/(tf.math.reduce_max(x) - tf.math.reduce_min(x))) * 255\n",
        "  print(norm.shape)\n",
        "  reshape_image = tf.reshape(norm, (60000, 28,28))\n",
        "  return reshape_image\n",
        "\n",
        "output = new_model(new_train_labels, training=False)\n",
        "created_images = norm_as_image(output)\n",
        "print(created_images.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0jWOHsy7wZf",
        "colab_type": "code",
        "outputId": "7b6dbb5c-c8b4-473c-932c-5222f780de4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "num = 18\n",
        "print(tf.argmax(train_labels[num]))\n",
        "plt.imshow(created_images[num], cmap='Greys')\n",
        "plt.show()\n",
        "\n",
        "as_input = tf.reshape(created_images[num], (1,28,28,1))\n",
        "print(\"prediction : \" + str(tf.argmax(trained_model.predict(as_input), -1)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "prediction : tf.Tensor([6], shape=(1,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i95vNEi17nVU",
        "colab_type": "text"
      },
      "source": [
        "## Try again with another new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjcUsoMun44-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_image_model2(trained_model):\n",
        "  inputs = keras.Input(shape=(10,))\n",
        "  dense1 = keras.layers.Dense(units=256, activation=tf.nn.relu)(inputs)\n",
        "  dense2 = keras.layers.Dense(units=512, activation=tf.nn.relu)(dense1)\n",
        "  dense3 = keras.layers.Dense(units=1024, activation=tf.nn.relu)(dense2)\n",
        "  drop1 = keras.layers.Dropout(rate=0.4)(dense3)\n",
        "  dense4 = keras.layers.Dense(units=1024, activation=tf.nn.relu)(drop1)\n",
        "  dense5 = keras.layers.Dense(units=2048, activation=tf.nn.relu)(dense4)\n",
        "  dense6 = keras.layers.Dense(units=784, activation=tf.nn.relu)(dense5)\n",
        "  dense7 = keras.layers.Dense(units=784, activation=tf.nn.relu)(dense6)\n",
        "  logits = keras.layers.Dense(units=784)(dense7)\n",
        "\n",
        "  activation = keras.layers.Activation(norm_as_activation)(logits)\n",
        "  trained_output = trained_model(activation, training=False)\n",
        "  return keras.Model(inputs=inputs, outputs=logits), keras.Model(inputs=inputs, outputs=trained_output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTZSIpmT3KZc",
        "colab_type": "code",
        "outputId": "fe507c45-0a85-4f47-ca6f-54affb884164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "trained_model = tf.keras.models.load_model(model_path)\n",
        "new_model2, ensemble_model2 = create_image_model2(trained_model)\n",
        "new_optimizer = keras.optimizers.Adam()\n",
        "new_train_labels = train_labels.copy()\n",
        "print(new_train_labels)\n",
        "\n",
        "ensemble_model2.compile(optimizer=new_optimizer, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "ensemble_model2.fit(new_train_labels, train_labels, epochs=2, batch_size=100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n",
            "Train on 60000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 168s 3ms/sample - loss: 0.0899 - accuracy: 0.9691\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 167s 3ms/sample - loss: 2.9537e-06 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e7c77ea20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38S5o4NP1i8t",
        "colab_type": "code",
        "outputId": "2f86e85d-80b6-45ff-d70b-d24998874eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "output = new_model2(new_train_labels, training=False)\n",
        "created_images = norm_as_image(output)\n",
        "print(created_images.shape)\n",
        "#print(created_images[0])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyeB3EUU3AsN",
        "colab_type": "code",
        "outputId": "e6774626-ab81-4e52-9588-1654109aa927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "num = 11239\n",
        "\n",
        "print(tf.argmax(train_labels[num]))\n",
        "plt.imshow(created_images[num], cmap='Greys')\n",
        "plt.show()\n",
        "\n",
        "as_input = tf.reshape(created_images[num], (1,28,28,1))\n",
        "print(\"prediction : \" + str(tf.argmax(trained_model.predict(as_input), -1)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "prediction : tf.Tensor([8], shape=(1,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp6CZzNQ5O08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}